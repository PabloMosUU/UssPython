{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a86b51",
   "metadata": {},
   "source": [
    "# Unit 3.3: Advanced Pandas\n",
    "\n",
    "This notebook is based on Anna-Lena Lamprecht's CoTaPP repository (https://github.com/annalenalamprecht/CoTaPP). Some modifications were made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a64d8a",
   "metadata": {},
   "source": [
    "Last time we discussed file I/O and the basics of Pandas.\n",
    "\n",
    "Now we have a look at more use cases of Pandas. Always keep in mind that in the lecture we can only discuss a few selected examples, so refer to the respective online documentation for full reference.\n",
    "\n",
    "Next time we will learn about data visualization with ```matplotlib```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b009cbc",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "The most important things to know about Pandas we have already covered in the last lecture: how to use Pandas to read content from CSV files, the ```DataFrame``` and ```Series``` data structures, indexing operations and basic plotting and statistics methods for data frames and series. Please refer to the [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable/) for further details, as we cannot cover the library in depth in this course. \n",
    "\n",
    "In this lecture we address some other important aspects: \n",
    "\n",
    "* handling of missing data\n",
    "\n",
    "* concatenating/joining tables with Pandas\n",
    "\n",
    "* grouping rows by a certain attribute\n",
    "\n",
    "* correlations of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5bd31",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n",
    "\n",
    "For various reasons it can happen that data are missing in a data frame. They might, for example, already have been missing in the input CSV file due to measurement faults, or have become unavailable because of computations that were not able to return a (good) result.\n",
    "In Pandas the value ```np.nan``` (technically of type ```float```) is the primarily used value for representing missing data. This can look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/table-with-missing-data.csv\", sep=\",\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1987c",
   "metadata": {},
   "source": [
    "By default, Pandas operations simply ignore ```NaN``` values. That is, they simply carry out the computation on the available data in the data frame or series, and/or propagate ```NaN``` values if a meaningful result cannot be derived. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a797a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8e465-ce69-47d2-bc61-73e4f0eb5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "(29+45+63+42+75+35)/6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c029d80-3ab5-4349-80e6-3ee75d2b0210",
   "metadata": {},
   "source": [
    "### Challenge!\n",
    "\n",
    "What do you expect should happen when you compute the average age?\n",
    "\n",
    "![](img/activity_small.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12602481",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb87bff-c297-4c94-9bfa-a8a6ba103c36",
   "metadata": {},
   "source": [
    "### Challenge!\n",
    "\n",
    "What do you expect should happen when you add 1 to each person's age?\n",
    "\n",
    "![](img/activity_small.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5c25e-97ec-4f3f-ad5b-494a28d2a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_next_year'] = df['age'] + 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a34413",
   "metadata": {},
   "source": [
    "If such behavior is not wanted, the data frame or series can be manipulated accordingly before applying the operations. One option is to remove rows or columns with missing data completely by using the ```dropna()``` function. The following example shows how to drop all rows where any data are missing, and how to drop all rows where age or height data are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe80310",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dropna())\n",
    "print(\"----------\")\n",
    "print(df.dropna(subset=[\"age\", \"height\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a99f35",
   "metadata": {},
   "source": [
    "Another possibility is to replace the ```NaN``` values by other/better values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----Replaced all missing values with 0-----\")\n",
    "print(df.fillna(0))\n",
    "print(\"-----Replaced all missing ages and heights with 0-----\")\n",
    "print(df.fillna(value={\"age\":0, \"height\":0}))\n",
    "print(\"-----Replaced all missing ages and heights with mean values-----\")\n",
    "print(df.fillna(value={\"age\":df[\"age\"].mean(), \\\n",
    "                       \"height\":df[\"height\"].mean()}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef7205c",
   "metadata": {},
   "source": [
    "Extra: In some cases also Pandas’ ```interpolate()``` function can be used to come up with values to fill in for missing data. Of course, replacing missing data with values should always be done with great care, as there is a risk of producing distorted or even wrong results when adding data to a data set. Generally, the choice how to handle missing data depends on the specifics of the concrete case, but it is good to know about the different options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ddee4",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "Suppose you have a dataset containing information about students, including their names, grades, and subjects. You want to calculate the average grade for each subject. \n",
    "\n",
    "### Challenge!\n",
    "\n",
    "How do you do this with the methods learnt so far?\n",
    "\n",
    "![](img/activity_small.png) \n",
    "\n",
    "#### Pandas `groupby`\n",
    "\n",
    "You can use the groupby function in pandas to group the data by subject and then calculate the average grade for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36aa16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob', 'Charlie'],\n",
    "    'Subject': ['Math', 'Math', 'Math', 'Science', 'Science', 'Science'],\n",
    "    'Grade': [85, 92, 78, 90, 88, 95]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group the data by subject and calculate the average grade\n",
    "grouped = df.groupby('Subject')['Grade'].mean()\n",
    "\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f094001",
   "metadata": {},
   "source": [
    "We can access the groups in a loop if we want to calculate other more complicated functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33221949",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl, grp in df.groupby('Subject'):\n",
    "    print(lbl, type(grp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cafe8f7",
   "metadata": {},
   "source": [
    "We can see that the label ```lbl``` corresponds to the unique values of the column \"Subject\", while each of the groups is of type ```DataFrame```. We might want to retrieve the name of the student who scored the highest grade on each subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl, grp in df.groupby('Subject'):\n",
    "    print(lbl, grp.sort_values('Grade', ascending=False)['Name'].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe10b6",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### 1. Analysis of the McDonald’s Menu (★★★★☆)\n",
    "This exercise is a variation of one that Dr. Adrien Melquiond (Utrecht Bioinformatics Center) developed in the scope of another Python course. It uses the Pandas library to analyze the dataset in the file `mcdonalds_menu.csv`, which provides a nutrition analysis of every menu item on the US McDonald's menu (including breakfast, beef burgers, chicken and fish sandwiches, fries, salads, soda, coffee and tea, milkshakes, and desserts). These data have been scraped from the McDonald's website. The assignment is basically about exploring how much fat and other nutrients contained in McDonald’s food. \n",
    "\n",
    "Write a program that reads the content of the file into a data frame, displays simple descriptive statistics about the numerical values in the data frame, and then answers the following questions (you might need Google’s help for some)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec43805",
   "metadata": {},
   "source": [
    "#### a. What do we have on the menu? \n",
    "How many different items do we have on the menu? Print the number of items per category. Which category is the most represented in this menu?\n",
    "\n",
    "The output should look something like:\n",
    "\n",
    "    Category\n",
    "    Beef & Pork           15\n",
    "    Beverages             27\n",
    "    Breakfast             42\n",
    "    Chicken & Fish        27\n",
    "    Coffee & Tea          95\n",
    "    Desserts               7\n",
    "    Salads                 6\n",
    "    Smoothies & Shakes    28\n",
    "    Snacks & Sides        13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92deace-588a-432a-a3b5-d342fadae952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Popularity'] = 1\n",
    "df.groupby('Category')['Item'].count().reset_index().sort_values('Item', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce98ce-a8cf-422b-a90d-4840c439f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Category'] == 'Beef & Pork'].sort_values('Calories', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5352c1b-917f-4786-9b2c-426c0baa3cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mcdonalds_menu.csv')\n",
    "for lbl, grp in df.groupby('Category'):\n",
    "    sub_grp = grp.sort_values('Calories', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0e2b5",
   "metadata": {},
   "source": [
    "#### b. What is the most fatty item for each category?\n",
    "Background information: When it comes to fat, trans fats are really the ones to avoid. Trans fat is a byproduct of a process called hydrogenation that is used to turn healthy oils into solids and to prevent them from becoming rancid. It increases the amount of harmful LDL cholesterol in the bloodstream. Cholesterol can be either good (HDL) or bad (LDL) but chances are slim that we are talking about the good one here. Saturated fat is not necessarily bad, but diet rich in saturated fat can drive up total cholesterol, with increased risk of clogged arteries. Unsaturated fat are not reported in this table.\n",
    "\n",
    "Create a subset data frame, called `grp_by_category`, that lists per category the maximal amount of 'Total Fat (% Daily Value)','Trans Fat','Saturated Fat (% Daily Value)' and 'Cholesterol (% Daily Value)'. Merge the data frames `menu` and `grp_by_category` and create a mask to select the items that correspond to the maximal 'Total Fat (% Daily Value)'. Be careful, you may end up with more than one fattest item per category. Repeating the same process, extract now the fattest item in 'Trans fat' (make sure to select only items with Trans fat > 0). Sort them by decreasing order of Trans fat, display the resulting data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415abd4",
   "metadata": {},
   "source": [
    "#### c. Is there anything healthy on the menu?\n",
    "Search for items with 0 'Trans fat' and 'Cholesterol (% Daily Value)', and maximum 20 'Sugars' and 'Total Fat (% Daily Value)'. Sort the healthy items per calories in ascending order. Remove from this healthy data frame all the drinks (beverages, coffee & tea).\n",
    "\n",
    "The output should look something like:\n",
    "\n",
    "![](img/mcdo_q3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d5cd8",
   "metadata": {},
   "source": [
    "#### d. What are the 10 items that have the highest content of Vitamin C?\n",
    "Citrus fruits are the high source of Vitamin C. For adults, the recommended dietary reference intake for vitamin C is 65 to 90 milligrams (mg) a day, and the upper limit is 2,000 mg a day. Show the 'Vitamin C (% Daily Value)' for the ten items that contain the highest amount of vitamin C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b02143",
   "metadata": {},
   "source": [
    "#### e. How do the nutrition features compare to each other?\n",
    "Let's finally take a look at how one feature feeds into the other. Using `pandas.DataFrame.corr`, we can compute the correlation coefficient of all the following columns in your dataframe: 'Calories', 'Total Fat', 'Saturated Fat', 'Cholesterol', 'Sodium', 'Carbohydrates', 'Sugars', 'Protein'. What can you observe from the (anti)correlations of the nutritional metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa8e87",
   "metadata": {},
   "source": [
    "## Extras\n",
    "The Anaconda website offers a number of *Learning Python For Data Science* [cheat sheets](https://www.anaconda.com/learning-python-data-science-cheat-sheets). Print out those that could be useful for quick reference when working on a project. In particular, that might be the cheat sheets about [Python basics](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PythonForDataScience.pdf) and [Pandas basics](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf), but there are some more that you might find interesting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
